{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import keras \n",
    "#from keras.models import load_model\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics\n",
    "from glob import glob\n",
    "import os\n",
    "from random import sample  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function reads in a .dcm file, checks the important fields for our device, and returns a numpy array\n",
    "# of just the imaging data\n",
    "\n",
    "def check_dicom(filename): \n",
    "\n",
    "    print('\\nLoad file {} ...'.format(filename))\n",
    "    ds = pydicom.dcmread(filename)\n",
    "    \n",
    "    # Optional: You can check some DICOM headers if needed\n",
    "    # e.g., Patient Position, Body Part Examined, etc.\n",
    "    if 'PatientPosition' in ds:\n",
    "        print('  Patient Position:', ds.PatientPosition)\n",
    "    if 'BodyPartExamined' in ds:\n",
    "        print('  Body Part Examined:', ds.BodyPartExamined)\n",
    "    if 'ImageType' in ds:\n",
    "        print('  Image Type:', ds.ImageType)\n",
    "    \n",
    "    img = ds.pixel_array\n",
    "    return img\n",
    "\n",
    "\n",
    "# This function takes the numpy array output by check_dicom and \n",
    "# runs the appropriate pre-processing needed for our model input\n",
    "def preprocess_image(img, img_mean, img_std, img_size): \n",
    "    # Normalizing using mean and std dev\n",
    "    img = (img - img_mean) / img_std\n",
    "    \n",
    "    # Resizing\n",
    "    img = resize(img, (img_size[1], img_size[2]))\n",
    "    \n",
    "    # Adding channel and batch dimensions\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    # If the model expects 3 channels (RGB), then duplicate the single channel 3 times\n",
    "    if img_size[3] == 3:\n",
    "        img = np.repeat(img, 3, axis=-1)\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "# This function loads in our trained model w/ weights and compiles it \n",
    "def load_my_model(model_path, weight_path):\n",
    "    model = load_model(model_path)\n",
    "    model.load_weights(weight_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "# This function uses our device's threshold parameters to predict whether or not\n",
    "# the image shows the presence of pneumonia using our trained model\n",
    "def predict_image(model, img, thresh): \n",
    "    pred = model.predict(img)\n",
    "    return (pred > thresh).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Load file test1.dcm ...\n",
      "  Patient Position: PA\n",
      "  Body Part Examined: CHEST\n",
      "  Prediction:  Negative\n",
      "\n",
      "Load file test2.dcm ...\n",
      "  Patient Position: AP\n",
      "  Body Part Examined: CHEST\n",
      "  Prediction:  Negative\n",
      "\n",
      "Load file test3.dcm ...\n",
      "  Patient Position: AP\n",
      "  Body Part Examined: CHEST\n",
      "  Prediction:  Negative\n",
      "\n",
      "Load file test4.dcm ...\n",
      "  Patient Position: PA\n",
      "  Body Part Examined: RIBCAGE\n",
      "  Prediction:  Negative\n",
      "\n",
      "Load file test5.dcm ...\n",
      "  Patient Position: PA\n",
      "  Body Part Examined: CHEST\n",
      "  Prediction:  Negative\n",
      "\n",
      "Load file test6.dcm ...\n",
      "  Patient Position: XX\n",
      "  Body Part Examined: CHEST\n",
      "  Prediction:  Negative\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "test_dicoms = ['test1.dcm','test2.dcm','test3.dcm','test4.dcm','test5.dcm','test6.dcm']\n",
    "model_path =  \"full_model2.h5\" #path to saved model\n",
    "weight_path = \"{}_my_model.best.hdf5\".format('xray_class2') #path to saved best weights\n",
    "\n",
    "IMG_SIZE = (1,224,224,3) # This might be different if you did not use vgg16\n",
    "img_mean = 0.50952472 # loads the mean image value they used during training preprocessing\n",
    "img_std = 0.24108991 # loads the std dev image value they used during training preprocessing\n",
    "\n",
    "#my_model = load_model(model_path, weight_path) #loads model\n",
    "my_model = load_model(\"full_model2.h5\")\n",
    "my_model.load_weights(\"{}_my_model.best.hdf5\".format('xray_class2'))\n",
    "thresh = 0.44483218 #loads the threshold they chose for model classification \n",
    "\n",
    "# use the .dcm files to test your prediction\n",
    "for i in test_dicoms:\n",
    "    \n",
    "    img = np.array([])\n",
    "    img = check_dicom(i)\n",
    "    \n",
    "    if img is None:\n",
    "        continue\n",
    "        \n",
    "    img_proc = preprocess_image(img,img_mean,img_std,IMG_SIZE)\n",
    "    pred = \"Positive\" if predict_image(my_model,img_proc,thresh) else \"Negative\"\n",
    "    print(\"  Prediction: \", pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Algorithm Limitation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scans found: 112120 , Total Headers 112120\n",
      "['Cardiomegaly' 'Emphysema' 'Effusion' 'No Finding' 'Hernia'\n",
      " 'Infiltration' 'Mass' 'Nodule' 'Atelectasis' 'Pneumothorax'\n",
      " 'Pleural_Thickening' 'Pneumonia' 'Fibrosis' 'Edema' 'Consolidation']\n"
     ]
    }
   ],
   "source": [
    "## Below is some helper code to read all of your full image filepaths into a dataframe for easier manipulation\n",
    "## Load the NIH data to all_xray_df\n",
    "all_xray_df = pd.read_csv('/data/Data_Entry_2017.csv')\n",
    "all_image_paths = {os.path.basename(x): x for x in \n",
    "                   glob(os.path.join('/data','images*', '*', '*.png'))}\n",
    "print('Scans found:', len(all_image_paths), ', Total Headers', all_xray_df.shape[0])\n",
    "all_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)\n",
    "\n",
    "# Split labels by the delimiter\n",
    "comorbid_diseases = all_xray_df['Finding Labels'].str.split('|').explode().unique()\n",
    "print(comorbid_diseases)\n",
    "\n",
    "for comorbid_disease in comorbid_diseases:\n",
    "    all_xray_df[comorbid_disease] = all_xray_df['Finding Labels'].str.contains(comorbid_disease).astype(int)\n",
    "\n",
    "all_xray_df['pneumonia_class'] = all_xray_df['Finding Labels'].str.contains('Pneumonia').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_splits(df):\n",
    "    \n",
    "    ## Either build your own or use a built-in library to split your original dataframe into two sets \n",
    "    ## that can be used for training and testing your model\n",
    "    ## It's important to consider here how balanced or imbalanced you want each of those sets to be\n",
    "    ## for the presence of pneumonia\n",
    "    \n",
    "    # Todo\n",
    "    train_data, val_data = train_test_split(df, test_size=0.2, stratify = df['Pneumonia'], random_state=42)\n",
    "    \n",
    "    return train_data, val_data\n",
    "\n",
    "# Use the function\n",
    "train_data, val_data = create_splits(all_xray_df)\n",
    "p_inds = val_data[val_data.Pneumonia==1].index.tolist()\n",
    "np_inds = val_data[val_data.Pneumonia==0].index.tolist()\n",
    "\n",
    "# The following code pulls a random sample of non-pneumonia data that's 4 times as big as the pneumonia sample.\n",
    "np_sample = sample(np_inds,4*len(p_inds))\n",
    "val_data = val_data.loc[p_inds + np_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1430 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "idg_val = ImageDataGenerator(rescale=1. / 255.0)\n",
    "val_gen = idg_val.flow_from_dataframe(dataframe=val_data, \n",
    "                                         directory=None, \n",
    "                                         x_col = 'path',\n",
    "                                         y_col = 'pneumonia_class',\n",
    "                                         class_mode = 'binary',\n",
    "                                         target_size = IMG_SIZE, \n",
    "                                         batch_size = 9\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 33s 210ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_Y = my_model.predict(val_gen, verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_predictions = np.where(pred_Y > thresh, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = sklearn.metrics.confusion_matrix(val_data['Pneumonia'],\n",
    "                                                  binary_predictions, labels=[0,1]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42657342657342656 0.5646853146853147\n"
     ]
    }
   ],
   "source": [
    "sens = tp/(tp+fn)\n",
    "spec = tn/(tn+fp)\n",
    "print(sens, spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
